#!/usr/bin/env python3
"""
Produce publication-ready figures that visualise the self-synchronised scan
segmentation pipeline. The script ingests segmented event archives generated by
``segment_robust_fixed.py`` and emits column-width figures ready for LaTeX:

    1. figure02_activity.pdf   – Activity trace with forward/backward shading
    2. figure02_correlation.pdf – Auto-/reverse-correlation diagnostics
    3. figure02_duration.pdf   – Half-scan duration distributions (supporting)
    4. figure02_eventrate.pdf  – Event-rate convergence over fused scans

Each figure leaves captioning to LaTeX; no panel letters are embedded in the
rendered graphics. Use LaTeX overlays (e.g., TikZ nodes) to place (a)/(b) labels.
"""

from __future__ import annotations

import argparse
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, List, Sequence, Tuple

import matplotlib.patches as mpatches
import matplotlib.pyplot as plt
from matplotlib.lines import Line2D
import numpy as np

REPO_ROOT = Path(__file__).resolve().parents[1]
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))
DEFAULT_SEGMENTS = (
    REPO_ROOT
    / "scan_angle_20_led_2835b"
    / "angle_20_blank_2835_20250925_184747"
    / "angle_20_blank_2835_event_20250925_184747_segments"
)
DEFAULT_OUTPUT_DIR = Path(__file__).resolve().parent / "figures"

from segment_robust_fixed import analyze_scanning_pattern, events_to_activity_signal
from simple_raw_reader import read_raw_simple


@dataclass
class SegmentInfo:
    """Metadata describing a forward or backward scan segment."""

    dataset: str
    scan_id: int
    direction: str
    start_us: int
    end_us: int
    event_count: int
    occupancy_us: float
    event_rate: float
    npz_path: Path


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Generate publication-quality figures for scan segmentation diagnostics."
    )
    parser.add_argument(
        "--dataset-path",
        type=Path,
        default=DEFAULT_SEGMENTS,
        help="Path to a *_segments directory produced by segment_robust_fixed.py.",
    )
    parser.add_argument(
        "--time-bin-us",
        type=int,
        default=1000,
        help="Temporal bin size in microseconds for plotting the activity trace (panel a).",
    )
    parser.add_argument(
        "--analysis-bin-us",
        type=int,
        default=None,
        help="Optional finer bin size (us) for scanning pattern analysis. If the coarse bin fails, falls back to 1000us.",
    )
    parser.add_argument(
        "--activity-fraction",
        type=float,
        default=0.90,
        help="Fraction of events used when detecting the densest window.",
    )
    parser.add_argument(
        "--raw-file",
        type=Path,
        help="Optional path to the RAW event file; inferred from dataset if omitted.",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=DEFAULT_OUTPUT_DIR,
        help="Directory where PDF/PNG figures will be written.",
    )
    parser.add_argument(
        "--save-png",
        action="store_true",
        help="Emit companion PNG renders for quick previews.",
    )
    return parser.parse_args()


def find_segment_dirs(base_dir: Path) -> List[Path]:
    """Locate *_segments directories under ``base_dir``."""

    if base_dir.is_dir() and base_dir.name.endswith("_segments"):
        return [base_dir]
    return [
        path
        for path in base_dir.rglob("*_segments")
        if path.is_dir() and any(path.glob("Scan_*_events.npz"))
    ]


def load_segment_infos(segment_dir: Path) -> List[SegmentInfo]:
    """Extract metadata for every segment within ``segment_dir``."""

    dataset_name = segment_dir.parent.name
    infos: List[SegmentInfo] = []
    for npz_path in sorted(segment_dir.glob("Scan_*_events.npz")):
        with np.load(npz_path) as data:
            start_us = int(data["start_time"])
            end_us = int(data["end_time"])
            scan_id = int(data["scan_id"])
            direction = str(data["direction"])
            event_count = int(data["event_count"])
            timestamps = data["t"].astype(np.int64)
        occupancy_us = float(timestamps[-1] - timestamps[0])
        duration_ms = (end_us - start_us) / 1000.0
        window_ms = duration_ms if duration_ms > 0 else max(occupancy_us / 1000.0, 1.0)
        event_rate = event_count / window_ms
        infos.append(
            SegmentInfo(
                dataset=dataset_name,
                scan_id=scan_id,
                direction=direction,
                start_us=start_us,
                end_us=end_us,
                event_count=event_count,
                occupancy_us=occupancy_us,
                event_rate=event_rate,
                npz_path=npz_path,
            )
        )
    return infos


def infer_raw_file(source: Path) -> Path:
    """Guess the RAW event file path relative to the provided dataset."""

    if source.is_file() and source.suffix == ".raw":
        return source

    search_roots = []
    if source.is_dir():
        if source.name.endswith("_segments"):
            search_roots.append(source.parent)
        search_roots.append(source)
    else:
        search_roots.append(source.parent)

    tried: List[Path] = []
    for root in search_roots:
        candidates = sorted(root.glob("*event*.raw"))
        if candidates:
            return candidates[0]
        tried.append(root)
    raise FileNotFoundError(
        f"Could not locate a RAW file near {source}. "
        f"Tried: {', '.join(str(p) for p in tried)}"
    )


def load_activity_from_raw(raw_path: Path, time_bin_us: int) -> Tuple[np.ndarray, np.ndarray, int]:
    """Read the RAW file and convert timestamps into an activity trace."""

    if read_raw_simple is None:
        raise RuntimeError(
            "simple_raw_reader is unavailable (Metavision HAL not installed). "
            "Re-run on a host with HAL or provide precomputed activity."
        )
    print(f"Loading RAW events from {raw_path} ...")
    _, _, t, _, width, height = read_raw_simple(str(raw_path))
    print(f"Sensor size: {width} x {height}")
    activity, t_min, _ = events_to_activity_signal(t, time_bin_us=time_bin_us)
    time_s = (np.arange(len(activity)) * time_bin_us + t_min) / 1_000_000.0
    return time_s, activity, t_min


## (No segments-only fallback here by design) — rely on RAW for fidelity


def setup_figure_style() -> None:
    plt.rcParams.update(
        {
            "font.size": 13.5,
            "axes.labelsize": 13.5,
            "axes.titlesize": 13.5,
            "axes.linewidth": 1.2,
            "xtick.direction": "out",
            "ytick.direction": "out",
            "xtick.major.size": 4.5,
            "ytick.major.size": 4.5,
            "legend.frameon": False,
        }
    )


def render_activity_figure(
    output_dir: Path,
    time_s: np.ndarray,
    activity: np.ndarray,
    results: dict,
    save_png: bool,
    bin_us: int,
) -> None:
    """Create the standalone activity figure."""

    fig, ax = plt.subplots(figsize=(5.0, 3.0))
    ax.plot(time_s, activity, color="#08306b", linewidth=1.1, zorder=2)

    prelude_end = time_s[min(results["scan_start"], len(time_s) - 1)]
    aftermath_start = time_s[min(results["scan_end"], len(time_s) - 1)]

    ax.axvspan(time_s[0], prelude_end, color="#fdd0a2", alpha=0.32, zorder=1)
    ax.axvspan(prelude_end, aftermath_start, color="#9ecae1", alpha=0.25, zorder=1)
    ax.axvspan(aftermath_start, time_s[-1], color="#d9d9d9", alpha=0.32, zorder=1)

    boundary_times: List[float] = []
    for i in range(results["n_cycles"] + 1):
        idx = results["scan_start"] + i * results["one_way_period"]
        if idx < results["scan_end"]:
            boundary_times.append(time_s[idx])
    boundary_times.append(time_s[min(results["scan_end"], len(time_s) - 1)])

    forward_line = Line2D([], [], color="#1f77b4", linestyle="--", linewidth=1.1, label="Forward boundary")
    backward_line = Line2D([], [], color="#d94801", linestyle="--", linewidth=1.1, label="Backward boundary")

    for i, t_boundary in enumerate(boundary_times[:-1]):
        color = "#1f77b4" if i % 2 == 0 else "#d94801"
        ax.axvline(t_boundary, color=color, linestyle="--", linewidth=1.1, alpha=0.9, zorder=3)

    # Label reflects plotting bin size
    ms = max(1, int(round(bin_us / 1000.0)))
    ax.set_ylabel(f"Events per {ms} ms bin")
    ax.set_xlabel("Time (s)")
    ax.set_xlim(time_s[0], time_s[-1])
    ymax = max(1.0, float(activity.max()))
    ax.set_ylim(0, ymax * 1.08)
    ax.grid(axis="y", linestyle=":", linewidth=0.6, alpha=0.4)
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    legend_handles = [
        mpatches.Patch(color="#fdd0a2", alpha=0.32, label="Pre-scan"),
        mpatches.Patch(color="#9ecae1", alpha=0.18, label="Scanning"),
        mpatches.Patch(color="#d9d9d9", alpha=0.32, label="Post-scan"),
        forward_line,
        backward_line,
    ]
    legend = ax.legend(
        handles=legend_handles,
        loc="upper left",
        fontsize=12,
        frameon=True,
    )
    legend.get_frame().set_facecolor("white")
    legend.get_frame().set_edgecolor("#d0d0d0")
    legend.get_frame().set_alpha(0.9)
    fig.tight_layout()

    pdf_path = output_dir / "figure02_activity.pdf"
    fig.savefig(pdf_path, dpi=400)
    if save_png:
        fig.savefig(output_dir / "figure02_activity.png", dpi=400)
    plt.close(fig)
    print(f"Saved activity figure to {pdf_path}")


def render_correlation_figure(
    output_dir: Path,
    lags_s: np.ndarray,
    auto_corr: np.ndarray,
    reverse_corr: np.ndarray,
    auto_peak_indices: List[int] | None,
    reverse_peak_index: int | None,
    save_png: bool,
) -> None:
    """Create the standalone correlation figure."""

    fig, ax = plt.subplots(figsize=(5.0, 3.0))
    auto_line_color = "#1f77b4"   # blue (line)
    center_dot_blue = "#0066cc"   # distinct blue for center peak
    side_dot_red = "#d62728"      # red for side peaks
    rev_line_color = "#d62728"    # solid red for reverse corr line

    ax.plot(lags_s, auto_corr, color=auto_line_color, linewidth=1.4, label="Auto-correlation")
    # Reverse correlation equals convolution with the time-reversed signal
    ax.plot(lags_s, reverse_corr, color=rev_line_color, linewidth=1.4, label="Auto-convolution")

    # Mark peaks: center (closest to 0 lag) in blue, side peaks in red
    if auto_peak_indices:
        # identify center by minimum |lag|
        valid = [i for i in auto_peak_indices if 0 <= i < len(lags_s)]
        if valid:
            center_idx = min(valid, key=lambda i: abs(lags_s[i]))
            side = [i for i in valid if i != center_idx]
            # center dot
            ax.scatter([lags_s[center_idx]], [auto_corr[center_idx]], color=center_dot_blue, s=40, zorder=5)
            # side dots
            if side:
                ax.scatter([lags_s[i] for i in side], [auto_corr[i] for i in side], color=side_dot_red, s=36, zorder=5)

    # Mark reverse-corr global peak with blue dot as requested
    if reverse_peak_index is not None and 0 <= reverse_peak_index < len(lags_s):
        ax.scatter([lags_s[reverse_peak_index]], [reverse_corr[reverse_peak_index]], color=center_dot_blue, s=42, zorder=5)

    ax.set_xlabel("Lag (s)")
    ax.set_ylabel("Normalised magnitude")
    # Choose x-limits to encompass all marked peaks (center/side and reverse)
    peak_positions: List[float] = []
    if auto_peak_indices:
        peak_positions += [float(lags_s[i]) for i in auto_peak_indices if 0 <= i < len(lags_s)]
    if reverse_peak_index is not None and 0 <= reverse_peak_index < len(lags_s):
        peak_positions.append(float(lags_s[reverse_peak_index]))
    if peak_positions:
        max_abs = max(abs(p) for p in peak_positions)
        target = min(max_abs + 0.3, 6.0)  # small padding; cap width at ±6 s
        ax.set_xlim(-target, target)
    else:
        ax.set_xlim(-4.0, 4.0)
    # Dynamic y-limits to avoid truncation on either series
    y_min = float(min(np.min(auto_corr), np.min(reverse_corr)))
    y_max = float(max(np.max(auto_corr), np.max(reverse_corr)))
    pad = 0.05 * (y_max - y_min if y_max > y_min else 1.0)
    ax.set_ylim(y_min - pad, y_max + pad)
    # No grid per request
    ax.grid(False)
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    # Annotate reverse-corr blue peak with its lag value
    # No text callout for reverse peak (keep blue dot only)

    legend = ax.legend(loc="upper left", fontsize=8, frameon=True)
    legend.get_frame().set_facecolor("white")
    legend.get_frame().set_edgecolor("#d0d0d0")
    legend.get_frame().set_alpha(0.9)
    fig.tight_layout()

    pdf_path = output_dir / "figure02_correlation.pdf"
    fig.savefig(pdf_path, dpi=400)
    if save_png:
        fig.savefig(output_dir / "figure02_correlation.png", dpi=400)
    plt.close(fig)
    print(f"Saved correlation figure to {pdf_path}")


def render_duration_figure(
    output_dir: Path,
    all_segments: Sequence[SegmentInfo],
    save_png: bool,
) -> None:
    """Create a supporting histogram of half-scan durations."""

    if not all_segments:
        return

    durations_s = np.array([seg.occupancy_us / 1_000_000.0 for seg in all_segments])
    directions = np.array([seg.direction for seg in all_segments])
    forward = durations_s[directions == "Forward"]
    backward = durations_s[directions == "Backward"]

    if forward.size == 0 or backward.size == 0:
        return

    bins = np.linspace(durations_s.min() * 0.98, durations_s.max() * 1.02, 16)
    fig, ax = plt.subplots(figsize=(6.1, 2.6))
    ax.hist(
        forward,
        bins=bins,
        histtype="step",
        linewidth=1.6,
        color="#1f77b4",
        label="Forward",
    )
    ax.hist(
        backward,
        bins=bins,
        histtype="step",
        linewidth=1.6,
        color="#d94801",
        label="Backward",
    )
    ax.set_xlabel("Half-scan duration (s)")
    ax.set_ylabel("Count")
    ax.grid(axis="y", linestyle=":", linewidth=0.5, alpha=0.5)
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.legend(loc="upper right", fontsize=8)
    ax.text(
        0.01,
        0.92,
        "Half-scan duration stability",
        transform=ax.transAxes,
        fontweight="bold",
        ha="left",
        va="top",
    )
    fig.subplots_adjust(top=0.85, bottom=0.22, left=0.12, right=0.97)
    fig.text(
        0.5,
        0.02,
        "Supplementary: duration distributions across forward/back scans.",
        ha="center",
        fontsize=9,
    )
    pdf_path = output_dir / "figure02_duration.pdf"
    fig.savefig(pdf_path, dpi=400)
    if save_png:
        fig.savefig(output_dir / "figure02_duration.png", dpi=400)
    plt.close(fig)
    print(f"Saved duration figure to {pdf_path}")


def render_eventrate_figure(
    output_dir: Path,
    segments: Sequence[SegmentInfo],
    save_png: bool,
) -> None:
    """Create a supporting plot showing cumulative event-rate convergence."""

    forward_rates = [seg.event_rate for seg in segments if seg.direction == "Forward"]
    backward_rates = [seg.event_rate for seg in segments if seg.direction == "Backward"]

    if not forward_rates or not backward_rates:
        return

    forward_cum = np.cumsum(forward_rates) / np.arange(1, len(forward_rates) + 1)
    backward_cum = np.cumsum(backward_rates) / np.arange(1, len(backward_rates) + 1)
    scans = np.arange(1, max(len(forward_cum), len(backward_cum)) + 1)

    fig, ax = plt.subplots(figsize=(6.1, 2.6))
    ax.plot(scans[: len(forward_cum)], forward_cum, marker="o", color="#1f77b4", label="Forward")
    ax.plot(scans[: len(backward_cum)], backward_cum, marker="s", color="#d94801", label="Backward")
    pooled_mean = np.mean(forward_rates + backward_rates)
    ax.axhline(pooled_mean, color="black", linestyle="--", linewidth=1.0, label="All scans mean")
    ax.set_xlabel("Number of fused scans")
    ax.set_ylabel("Events per ms")
    ax.set_xticks(scans)
    ax.grid(True, linestyle=":", linewidth=0.5, alpha=0.5)
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.legend(loc="upper right", fontsize=8)
    ax.text(
        0.01,
        0.92,
        "Multi-pass event-rate convergence",
        transform=ax.transAxes,
        fontweight="bold",
        ha="left",
        va="top",
    )
    fig.subplots_adjust(top=0.85, bottom=0.22, left=0.12, right=0.97)
    fig.text(
        0.5,
        0.02,
        "Supplementary: cumulative event-rate stabilises with additional scans.",
        ha="center",
        fontsize=9,
    )
    pdf_path = output_dir / "figure02_eventrate.pdf"
    fig.savefig(pdf_path, dpi=400)
    if save_png:
        fig.savefig(output_dir / "figure02_eventrate.png", dpi=400)
    plt.close(fig)
    print(f"Saved event-rate figure to {pdf_path}")


def main() -> None:
    args = parse_args()
    dataset_path = args.dataset_path.expanduser().resolve()
    output_dir = args.output_dir.expanduser().resolve()
    output_dir.mkdir(parents=True, exist_ok=True)

    segment_dirs = find_segment_dirs(dataset_path)
    target_segments: List[SegmentInfo] = []
    all_segments: List[SegmentInfo] = []
    if segment_dirs:
        target_segments = load_segment_infos(segment_dirs[0])
        root_for_segments = segment_dirs[0].parents[1]
        for seg_dir in find_segment_dirs(root_for_segments):
            all_segments.extend(load_segment_infos(seg_dir))

    raw_path = args.raw_file.expanduser().resolve() if args.raw_file else infer_raw_file(
        segment_dirs[0] if segment_dirs else dataset_path
    )
    # Build plotting activity (panel a)
    time_s, activity, t_min_coarse = load_activity_from_raw(raw_path, args.time_bin_us)

    # Try analysis on the plotting bins; if it fails, retry with a finer bin (default 1000us)
    results = analyze_scanning_pattern(activity, activity_fraction=args.activity_fraction, max_iterations=2)
    corr_bin_us = args.time_bin_us
    if not results:
        analysis_bin_us = args.analysis_bin_us if args.analysis_bin_us else 1000
        time_s_fine, activity_fine, t_min_fine = load_activity_from_raw(raw_path, analysis_bin_us)
        results_fine = analyze_scanning_pattern(activity_fine, activity_fraction=args.activity_fraction, max_iterations=2)
        if not results_fine:
            raise RuntimeError("Scanning analysis failed on both coarse and fine bins.")
        # Map fine-bin indices to coarse-bin indices
        scan_start_us = int(t_min_fine + results_fine["scan_start"] * analysis_bin_us)
        scan_end_us = int(t_min_fine + results_fine["scan_end"] * analysis_bin_us)
        one_way_us = int(results_fine["one_way_period"] * analysis_bin_us)
        scan_start_idx = max(0, int(round((scan_start_us - t_min_coarse) / args.time_bin_us)))
        scan_end_idx = max(0, int(round((scan_end_us - t_min_coarse) / args.time_bin_us)))
        one_way_bins = max(1, int(round(one_way_us / args.time_bin_us)))
        n_cycles = max(1, int((scan_end_idx - scan_start_idx) // one_way_bins))
        results = dict(results_fine)
        results.update(
            {
                "scan_start": scan_start_idx,
                "scan_end": scan_end_idx,
                "one_way_period": one_way_bins,
                "n_cycles": n_cycles,
            }
        )
        corr_bin_us = analysis_bin_us
        # Keep autocorr/reverse_corr from fine analysis
        activity = activity  # plotting remains coarse

    auto_corr = results["autocorr"]
    reverse_corr = results["reverse_corr"]
    # Build symmetric lag axis matching the full correlation length (2N-1)
    L = int(len(auto_corr))
    half = (L - 1) // 2
    lags_ms = np.arange(-half, half + 1, dtype=np.int64) * (corr_bin_us / 1000.0)
    lags_s = lags_ms / 1000.0
    one_way_s = results["one_way_period"] * (corr_bin_us / 1_000_000.0)
    turnaround_s = results["reverse_peak_lag"] * (corr_bin_us / 1_000_000.0)

    setup_figure_style()
    render_activity_figure(
        output_dir=output_dir,
        time_s=time_s,
        activity=activity,
        results=results,
        save_png=args.save_png,
        bin_us=args.time_bin_us,
    )
    # Prepare peak indices for panel (b)
    auto_peak_indices = results.get("autocorr_peaks", [])
    reverse_peak_index = results.get("center_idx", 0) + results.get("reverse_peak_lag", 0)

    render_correlation_figure(
        output_dir=output_dir,
        lags_s=lags_s,
        auto_corr=auto_corr,
        reverse_corr=reverse_corr,
        auto_peak_indices=auto_peak_indices,
        reverse_peak_index=reverse_peak_index,
        save_png=args.save_png,
    )
    render_duration_figure(output_dir=output_dir, all_segments=all_segments, save_png=args.save_png)
    render_eventrate_figure(output_dir=output_dir, segments=target_segments, save_png=args.save_png)


if __name__ == "__main__":
    main()
