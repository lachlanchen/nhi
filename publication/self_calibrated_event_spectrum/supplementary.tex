\documentclass[9pt,twocolumn]{opticajnl}
\journal{opticajournal}
\setboolean{shortarticle}{true}

% Keep typography and packages consistent with the main Optica letter
\IfFileExists{siunitx.sty}{%
  \usepackage{siunitx}
  \sisetup{range-phrase = --, range-units = single}
  \sisetup{per-mode = symbol}
}{%
  \newcommand{\sisetup}[1]{}
  \newcommand{\SI}[2]{\ensuremath{##1\,##2}}
  \newcommand{\SIrange}[3]{\ensuremath{##1\text{--}##2\,##3}}
  \newcommand{\DeclareSIUnit}[2]{}
}
\providecommand{\nano}{\ensuremath{\mathrm{n}}}
\providecommand{\micro}{\ensuremath{\mu}}
\providecommand{\milli}{\ensuremath{\mathrm{m}}}
\providecommand{\second}{\ensuremath{\mathrm{s}}}
\providecommand{\meter}{\ensuremath{\mathrm{m}}}
\providecommand{\per}{\ensuremath{\,/\,}}
\providecommand{\pixel}{\ensuremath{\mathrm{px}}}
\providecommand{\USD}{\ensuremath{\mathrm{USD}}}
\DeclareSIUnit{\pixel}{px}
\DeclareSIUnit{\USD}{USD}
\usepackage{xcolor}

\title{Supplementary Material: Self-Calibrated Neuromorphic Hyperspectral Sensing}
\author[]{Rongzhou Chen}
\author[]{Chutian Wang}
\author[]{Yuqing Cao}
\author[*]{Edmund Y. Lam}
\affil[]{Department of Electrical and Electronic Engineering, The University of Hong Kong, Pokfulam, Hong Kong SAR, China}
\affil[*]{elam@eee.hku.hk}
\dates{\today}

\begin{abstract}
This document provides supplementary methods, implementation notes, and additional figures supporting the main manuscript titled ``Self-Calibrated Neuromorphic Hyperspectral Sensing.'' 
\end{abstract}

\begin{document}

\maketitle

% Simple section helper matching main style
\newcommand{\olsection}[1]{\par\noindent\textbf{#1.} }

% \olsection{Additional Methods}
% The procedures below mirror the methodology detailed in the main letter.
% We briefly summarize details that complement the main text:
% \begin{itemize}
%   \item Scan segmentation uses the activity auto-correlation and auto-convolution peaks to determine the one-way period and pre/post regions.
%   \item Multi-window compensation fits linear boundary surfaces per window and optimizes spatial variance within fixed temporal bins to undo temporal shear.
%   \item Spectral displays use 50~ms cumulative bins unless otherwise noted; background subtraction and light smoothing may be applied for visibility.
% \end{itemize}

\olsection{Event-trigger probability model}
Event emission occurs when the logarithmic brightness increment surpasses a fixed magnitude $\theta$. Under realistic sensing conditions the observed gradient is corrupted by noise, which we model as
\begin{equation}
  \nabla I = \nabla I_{\text{true}} + \eta,\qquad \eta \sim \mathcal{N}(0,\sigma^2).
  \label{eq:gradient_noise}
\end{equation}

The probability of a positive event equals the likelihood that the noise-perturbed gradient exceeds the threshold,
\begin{equation}
  P(\text{event}) = P(\eta > \theta - \nabla I_{\text{true}}) = \tfrac12\!\left[1 - \operatorname{erf}\!\left(\frac{\theta - \nabla I_{\text{true}}}{\sqrt{2}\sigma}\right)\right],
  \label{eq:trigger_probability}
\end{equation}
with an analogous form for negative events around $-\theta$. Approximating the error function by a logistic curve yields the computationally convenient sigmoid expression
\begin{equation}
  P(\text{event}) \approx \sigma\!\left(\frac{\nabla I_{\text{true}} - \theta}{\sigma'}\right),\qquad \sigma' \approx \frac{2\sqrt{2}}{\sqrt{\pi}}\sigma,
  \label{eq:sigmoid_probability}
\end{equation}
where $\sigma(\cdot)$ denotes the logistic sigmoid. Within a temporal bin of duration $\Delta t$ the expected event count relates directly to this probability,
\begin{equation}
  \langle N_{\text{evt}}\rangle = \lambda\,P(\text{event})\,\Delta t,
  \label{eq:expected_events}
\end{equation}
with $\lambda$ the effective sampling rate per pixel. Averaging events over repeated scans gives the empirical mean $\bar{N}_{\text{evt}}$, which can be inverted via the logit function $\sigma^{-1}$ to estimate the true gradient:
\begin{equation}
  \nabla I_{\text{est}} = \theta + \sigma'\,\sigma^{-1}\!\left(\frac{\bar{N}_{\text{evt}}}{\lambda\,\Delta t}\right).
  \label{eq:gradient_estimate}
\end{equation}

This probabilistic link between event statistics and intensity gradients underpins the reconstruction strategy in the main letter. Equation~(\ref{eq:gradient_estimate}) justifies using temporally binned events as sufficient statistics for spectral estimation: the scan-induced evolution of $\nabla I_{\text{true}}$ encodes spectral slopes, while averaging suppresses sensor noise and preserves the dynamic-range benefits of event vision. Subsequent steps segment scans and correct residual temporal shear before building the spectral cube.

\olsection{Time--wavelength auto-alignment details}
The background trace $b(t)$ is sampled at $\Delta t{=}5$~ms and normalised by its pre/post plateaus,
\[
  \tilde b(t)=\frac{b(t)-\mu_{\mathrm{pre}}}{\mu_{\mathrm{post}}-\mu_{\mathrm{pre}}},\quad t\in[0,T].
\]
The active interval $[t_0,t_1]$ is located from the rising and falling edge quantiles of the smoothed $\tilde b(t)$: $t_0$ is the first crossing of a lower edge level, and $t_1$ is the last crossing of the corresponding upper edge level, locking the start and tail plateaus. For ground-truth spectra $\{g_i(\lambda)\}_{i=1}^M$ with active intervals $[\lambda_{0,i},\lambda_{1,i}]$, we fit an affine map
\[
  \lambda(t)=\alpha t+\beta,\quad 
  \alpha=\frac{\bar\lambda_1-\bar\lambda_0}{t_1-t_0},\;
  \beta=\bar\lambda_0-\alpha t_0,
\]
where $\bar\lambda_0,\bar\lambda_1$ are mean boundaries. The transformed series $\tilde b_\lambda(\lambda)=\tilde b\big((\lambda-\beta)/\alpha\big)$ is amplitude-aligned to the mean ground-truth $\bar g(\lambda)$ via a least-squares affine fit,
\[
  (a^*,c^*)=\arg\min_{a,c}\sum_j[\bar g(\lambda_j)-a\,\tilde b_\lambda(\lambda_j)-c]^2,
\]
with closed form $[a^*,c^*]^\top=(X^\top X)^{-1}X^\top\mathbf{y}$ for $X=[\tilde b_\lambda\;\mathbf{1}]$, $\mathbf{y}=\bar g$.

% \olsection{Supplementary Figure S1}
% Figure~\ref{fig:s1} shows the aligned background (event-derived) against a spectrometer curve, formatted as in the main text.

% \begin{figure}[t]
%   \centering
%   \includegraphics[width=\columnwidth]{figures/figure04_rescaled_bg_gt_third_only.pdf}
%   \caption{Background mapped to wavelength (blue) overlaid with Light SPD (orange). Legend placed inside, consistent with Fig.~5 styling.}
%   \label{fig:s1}
% \end{figure}

% \olsection{Segment Fusion Performance}
% We compare reconstruction noise across three fusion settings using a single dataset (\texttt{angle\_20\_sanqin\_2835\_20250925\_184638}) and 50~ms temporal bins:
% \begin{itemize}
%   \item Forward only (F): first forward segment.
%   \item Forward+Backward (F+B): first forward plus one backward (time-reversed, polarity-flipped).
%   \item Three cycles (3~F+B): up to six segments (F1,B2,F3,B4,F5,B6).
% \end{itemize}
% Learned parameters $(a,b)$ from the first forward segment are reused for all segments. For backward segments we reverse time ($t' = t_{\min}+t_{\max}-t$) and negate polarity (mapping 0/1 to $1{-}p$, or simply $-p$ in $\{-1,1\}$ form). Fused frames are averaged per-bin across segments, then background-subtracted prior to metric computation.

% Figure~\ref{fig:s2} shows the first 20 bins for each scenario. Table~\ref{tab:fusion_metrics} reports spatial standard deviation (STD) and median absolute deviation (MAD) averaged over bins.

% \begin{figure*}[t]
%   \centering
%   % Local copies for stable LaTeX inclusion
%   \includegraphics[width=0.96\textwidth]{figures_sm/forward_only_montage.pdf}\\[-2pt]
%   \includegraphics[width=0.96\textwidth]{figures_sm/f_plus_b_montage.pdf}\\[-2pt]
%   \includegraphics[width=0.96\textwidth]{figures_sm/three_cycles_f_plus_b_montage.pdf}
%   \caption{Supplementary Figure S2: First 20 binned frames (50~ms each). Top: Forward only; Middle: Forward+Backward; Bottom: Three F+B cycles.}
%   \label{fig:s2}
% \end{figure*}

% \begin{table}[t]
% \centering
% \caption{Average spatial noise per scenario (50~ms bins).}
% \label{tab:fusion_metrics}
% \begin{tabular}{lcc}
% \hline
% \textbf{Scenario} & \textbf{STD} & \textbf{MAD} \\
% \hline
% Forward only & 0.4322 & 0.0000 \\
% F + B & 0.3301 & 0.1235 \\
% 3\,$\times$\,(F + B) & 0.2403 & 0.1166 \\
% \hline
% \end{tabular}
% \end{table}

% \olsection{Reproducibility: Segment Fusion}
% The following command generates the figures and metrics above:
% \begin{itemize}
%   \item \texttt{python publication\_code/compare\_segment\_fusion.py \\
%     --dataset scan\_angle\_20\_led\_2835b/angle\_20\_sanqin\_2835\_20250925\_184638 \\
%     --bin-width-us 50000 --sensor-width 1280 --sensor-height 720 \\
%     --save-png --save-pdf}
% \end{itemize}

% \olsection{Reproducibility Notes}
% The following commands (run in the \texttt{nhi\_test} environment) regenerate the figures referenced here:
% \begin{itemize}
%   \item Figure 4 grid and overlay:
% \texttt{python publication\_code/figure04\_rescaled\_allinone.py \\
%   --segment scan\_angle\_20\_led\_2835b/angle\_20\_sanqin\_2835\_20250925\_184638/angle\_20\_sanqin\_2835\_event\_20250925\_184638\_segments/Scan\_1\_Forward\_events.npz \\
%   --gt-dir groundtruth\_spectrum\_2835 \\
%   --gt-frames-dir hyperspectral\_data\_sanqin\_gt/test300\_roi\_square\_frames\_matched \\
%   --bin-width-us 50000 --start-bin 3 --end-bin 15 --show-wavelength \\
%   --add-gt-row --bar-height-ratio 0.06 --bar-px 4 --save-png}
% \end{itemize}

\bibliography{ref}

\end{document}
